{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>3 seconds 593 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.3.3</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python_abhishek_zej259</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>1.76 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.12</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  ---------------------------------------\n",
       "H2O cluster uptime:             3 seconds 593 milliseconds\n",
       "H2O cluster version:            3.8.3.3\n",
       "H2O cluster name:               H2O_started_from_python_abhishek_zej259\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  1.76 GB\n",
       "H2O cluster total cores:        4\n",
       "H2O cluster allowed cores:      4\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.12\n",
       "------------------------------  ---------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import h2ohyperopt\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Processing\n",
    "The test dataset used for demonstrating the capabilities of H2OHyperopt is the titanic dataset. The function ```data()``` is used to preprocess the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    \"\"\"\n",
    "    Function to process the example titanic dataset.\n",
    "    Train-Valid-Test split is 60%, 20% and 20% respectively.\n",
    "    Output\n",
    "    ---------------------\n",
    "    trainFr: Training H2OFrame.\n",
    "    testFr: Test H2OFrame.\n",
    "    validFr: Validation H2OFrame.\n",
    "    predictors: List of predictor columns for the Training frame.\n",
    "    response: String defining the response column for Training frame.\n",
    "    \"\"\"\n",
    "    titanic_df = h2o.import_file(path=\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "    columns_to_be_used = ['pclass', 'age', 'sex', 'sibsp', 'parch', 'ticket',\n",
    "                          'embarked', 'fare', 'survived']\n",
    "    columns_to_factorize = ['pclass', 'sex', 'sibsp', 'embarked', 'survived']\n",
    "    # Factorizing the columns in the columns_to_factorize list\n",
    "    for col in columns_to_factorize:\n",
    "        titanic_df[col] = titanic_df[col].asfactor()\n",
    "    # Selecting only the columns we need\n",
    "    titanic_frame = titanic_df[columns_to_be_used]\n",
    "    trainFr, testFr, validFr = titanic_frame.split_frame([0.6, 0.2],\n",
    "                                                         seed=1234)\n",
    "    predictors = trainFr.names[:]\n",
    "    # Removing the response column from the list of predictors\n",
    "    predictors.remove('survived')\n",
    "    response = 'survived'\n",
    "    return trainFr, testFr, validFr, predictors, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "trainFr, testFr, validFr, predictors, response = data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mutiple Model Type Based Optimization\n",
    "Let us demonstrate the ModelDocker. Since the problem is a binary classification problem, we specify the metric to AUC. Docking three types of models - GBM's, GLM's and DLE's,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_gbm = h2ohyperopt.GBMOptimizer(metric='auc')\n",
    "# To use the default search space\n",
    "# model_gbm.select_optimization_parameters(\"Default\")\n",
    "# To use a combination of Default parameters and the customized parameters.\n",
    "model_gbm.select_optimization_parameters({'col_sample_rate': 'Default',\n",
    "                                          'ntrees': 200,\n",
    "                                          'learn_rate': ('uniform',(0.05, 0.2)),\n",
    "                                          'nfolds': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_dle = h2ohyperopt.DLEOptimizer(metric='auc')\n",
    "# Selecting parameters to optimize on\n",
    "model_dle.select_optimization_parameters({'epsilon': 'Default',\n",
    "                                          'adaptive_rate': True,                                           \n",
    "                                          'hidden': ('choice', [[10, 20], [30, 40]]),\n",
    "                                          'nfolds':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_glm = h2ohyperopt.GLMOptimizer(metric='auc', problemType='Classification')\n",
    "# Selecting default parameters to optimize on\n",
    "model_glm.select_optimization_parameters('Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Starting the Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The optimization is started using the function ```start_optimization```. It is necessary to provide a validation frame so that the optimization algorithm can evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n",
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n",
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "docker = h2ohyperopt.ModelDocker([model_dle, model_gbm, model_glm], 'auc')                                     \n",
    "docker.start_optimization(num_evals=20, trainingFr=trainFr,\n",
    "                          validationFr=validFr, response=response,                                              \n",
    "                          predictors=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics available to User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#To access the best model\n",
    "bestmodel = docker.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H2OGradientBoostingEstimator',\n",
       " {'col_sample_rate': 0.6783596802934229,\n",
       "  'learn_rate': 0.058252049654680824,\n",
       "  'metric': 'auc',\n",
       "  'nfolds': 7,\n",
       "  'ntrees': 200})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the best model parameters\n",
    "docker.best_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss metric(auc) is : 0.995106776992\n",
      "The validation loss metric(auc) is : 0.855424871151\n"
     ]
    }
   ],
   "source": [
    "# To get the training and validation scores\n",
    "docker.best_model_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Three ensemble methods provided for the user.<br \\>\n",
    "1. Use the best n models from evaluated models\n",
    "2. Use the best n models from each model class\n",
    "3. Smart ensembling using correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#To use best in class ensembling\n",
    "docker.best_in_class_ensembles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glm prediction Progress: [##################################################] 100%\n",
      "\n",
      "gbm prediction Progress: [##################################################] 100%\n",
      "\n",
      "deeplearning prediction Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "testDockerScore = docker.score_ensemble(testFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7503803888419274"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDockerScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ModelDocker instance has no attribute 'smart_ensembling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1ab332687525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#To use smart ensembling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdocker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_ensembling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: ModelDocker instance has no attribute 'smart_ensembling'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "#To use smart ensembling\n",
    "docker.smart_ensembling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
